---
title: "Week 4 Report"
author: "Giles Carlos"
date: '2022-07-19'
output: html_document
---

# Libraries

```{r}
#install.packages("runner")
library(tidyverse)
library(R.matlab)
library(janitor)
library(readr)
library(dplyr)
library(runner)
library(gridExtra)
library(caret)
library(InformationValue)
library(ISLR)
library(nnet)
library(broom)
library(ggplot2); theme_set(theme_bw())
library(ggstance)
library(devtools)
#install_github("vqv/ggbiplot")
library(ggbiplot)
library(summarytools)
library(neuralnet)
library(pls)
library(leaps)
library(caret)
library(glmnet)
```

# Loading in Data

```{r}
behavior_m <- readMat(here::here("data/superchris_BM.mat"))
ensemble_m <- readMat(here::here("data/superchris_EM_onlyspikes_c.mat"))
```

# Cleaning Data

### Pulling from List

```{r}
em <- data.frame(ensemble_m[1])
bm <- data.frame(behavior_m[1]) 
col_names <- behavior_m[2][1]
```

### Renaming variables 

```{r}
bm <-
  bm %>%
  dplyr::rename(time_bin = behavMatrix.1,
         odor_1 = behavMatrix.2,
         odor_2 = behavMatrix.3,
         odor_3 = behavMatrix.4,
         odor_4 = behavMatrix.5,
         odor_5 = behavMatrix.6,
         position_1 = behavMatrix.7,
         position_2 = behavMatrix.8,
         position_3 = behavMatrix.9,
         position_4 = behavMatrix.10,
         position_5 = behavMatrix.11,
         in_seq_log = behavMatrix.12,
         performance_log = behavMatrix.13,
         poke_events = behavMatrix.14,
         front_reward = behavMatrix.15,
         back_reward = behavMatrix.16,
         x_val_pos = behavMatrix.17,
         y_val_pos = behavMatrix.18)
  
bm <- clean_names(bm)
  
em <- subset(em, select = -c(EM.1) )

em <- 
  em %>%
  dplyr::rename(neuron_1 = EM.2,
         neuron_2 = EM.3,
         neuron_3 = EM.4,
         neuron_4 = EM.5,
         neuron_5 = EM.6,
         neuron_6 = EM.7,
         neuron_7 = EM.8,
         neuron_8 = EM.9,
         neuron_9 = EM.10,
         neuron_10 = EM.11,
         neuron_11 = EM.12,
         neuron_12 = EM.13,
         neuron_13 = EM.14,
         neuron_14 = EM.15,
         neuron_15 = EM.16,
         neuron_16 = EM.17,
         neuron_17 = EM.18,
         neuron_18 = EM.19,
         neuron_19 = EM.20,
         neuron_20 = EM.21,
         neuron_21 = EM.22,
         neuron_22 = EM.23,
         neuron_23 = EM.24,
         neuron_24 = EM.25,
         neuron_25 = EM.26,
         neuron_26 = EM.27,
         neuron_27 = EM.28,
         neuron_28 = EM.29,
         neuron_29 = EM.30,
         neuron_30 = EM.31,
         neuron_31 = EM.32,
         neuron_32 = EM.33,
         neuron_33 = EM.34,
         neuron_34 = EM.35,
         neuron_35 = EM.36,
         neuron_36 = EM.37,
         neuron_37 = EM.38,
         neuron_38 = EM.39,
         neuron_39 = EM.40,
         neuron_40 = EM.41,
         neuron_41 = EM.42,
         neuron_42 = EM.43,
         neuron_43 = EM.44,
         neuron_44 = EM.45,
         neuron_45 = EM.46,
         neuron_46 = EM.47)
  
em <- clean_names(em)
```

### changing variable types

```{r}
bm <-
  bm %>%
  mutate(odor_1 = as.integer(odor_1),
         odor_2 = as.integer(odor_2),
         odor_3 = as.integer(odor_3),
         odor_4 = as.integer(odor_4),
         odor_5 = as.integer(odor_5),
         position_1 = as.integer(position_1),
         position_2 = as.integer(position_2),
         position_3 = as.integer(position_3),
         position_4 = as.integer(position_4),
         position_5 = as.integer(position_5),
         in_seq_log = as.integer(in_seq_log),
         performance_log = as.integer(performance_log),
         poke_events = as.integer(poke_events),
         front_reward = as.integer(front_reward),
         back_reward = as.integer(back_reward))
glimpse(bm)
```

# Adding Trial Column in Behavior Matrix

```{r}
# Focus on time_bin and poke_events variables in the bm data frame
# Filter when the rat pokes in and pokes out (trial starts and ends)
# Convert all -1s in poke_events column to 1s
# Every 2 rows represents the start of a trial and the end of a trial
# Taking the ceiling of the cumulative sum of poke_event divided by 2 gives us the appropriate trial number for every two rows
bm_trials <- bm %>% 
  select(time_bin, poke_events) %>% 
  filter(poke_events != 0) %>% 
  mutate(poke_events = case_when(poke_events != 0 ~ 1,
                                 poke_events == 0 ~ 0)) %>% 
  mutate(trial = as.integer(ceiling(cumsum(poke_events) / 2))) %>% 
  select(time_bin, trial) 

# merging the trial column with the original bm data frame
# trials column will now have NAs when time_bin has no overlap
bm <- bm %>% 
  left_join(bm_trials, by = c("time_bin")) 
  
# making sure there are 240 trials
bm_trials %>% 
  tail()

# Filling in gaps between trial start and trial end
# The reamining NAs should just be 0 (trial 0 == dead period)
bm <- bm %>% 
  mutate(trial = runner::fill_run(trial, only_within = TRUE)) %>% 
  replace_na(list(trial = 0))
```

# Merging Trials and Time with Ensemble Matrix (Neurons)

```{r}
# merging the following variables with the ensemble matrix storing the neurons firing activity
em_trials <- bm %>% 
  select(time_bin, trial, odor_1, odor_2, odor_3, odor_4, odor_5,
         position_1, position_2, position_3, position_4, position_5) %>% 
  cbind(em) 
```

### Creating Odor Column (Response) Variable

```{r}
odor_1_trials <- em_trials %>% 
  filter(odor_1 == 1 & position_1 == 1) %>% 
  select(trial) %>% 
  pull()

odor_2_trials <- em_trials %>% 
  filter(odor_2 == 1 & position_2 == 1) %>% 
  select(trial) %>% 
  pull()

odor_3_trials <- em_trials %>% 
  filter(odor_3 == 1 & position_3 == 1) %>% 
  select(trial) %>% 
  pull()

odor_4_trials <- em_trials %>% 
  filter(odor_4 == 1 & position_4 == 1) %>% 
  select(trial) %>% 
  pull()

odor_5_trials <- em_trials %>% 
  filter(odor_5 == 1 & position_5 == 1) %>% 
  select(trial) %>% 
  pull()
```


```{r}
em_trials_odors <- em_trials %>% 
  filter(trial != 0) %>% 
  mutate(
    odor_1 = case_when(
      trial %in% odor_1_trials ~ 1,
      !(trial %in% odor_1_trials) ~ 0),
    odor_2 = case_when(
      trial %in% odor_2_trials ~ 1,
      !(trial %in% odor_2_trials) ~ 0),
    odor_3 = case_when(
      trial %in% odor_3_trials ~ 1,
      !(trial %in% odor_3_trials) ~ 0),
    odor_4 = case_when(
      trial %in% odor_4_trials ~ 1,
      !(trial %in% odor_4_trials) ~ 0),
    odor_5 = case_when(
      trial %in% odor_5_trials ~ 1,
      !(trial %in% odor_5_trials) ~ 0)
  ) %>% 
  mutate(odor = case_when(
    odor_1 == 1 ~ 1,
    odor_2 == 1 ~ 2,
    odor_3 == 1 ~ 3,
    odor_4 == 1 ~ 4,
    odor_5 == 1 ~ 5,
  )) 


```

# Creating Training Data Using 0 to 250 ms Window

```{r}
start_window <- 1
end_window <- 250 
window_size <- end_window - start_window

train <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(start_window:end_window) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial)
  #drop_na(odor)
  
test <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(-(start_window:end_window)) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial) 
  #drop_na(odor)

trial_times <- em_trials_odors %>% 
  group_by(trial) %>% 
  dplyr::summarise(trial_time_ms = n()) %>% 
  pull()

test_trial_times <- trial_times - window_size
train_trial_times <- trial_times - test_trial_times

test_rates <- test
train_rates <- train

train_odors <- train %>% 
  select(odor)
test_odors <- test %>% 
  select(odor)

test_rates <- test_rates %>% 
  select(-odor) 
train_rates <- train_rates %>% 
  select(-odor) 

test_rates <- test_rates / trial_times
train_rates <- train_rates / trial_times
  
train_rates <- cbind(train_rates, train_odors) %>% 
  drop_na(odor)
test_rates <- cbind(test_rates, test_odors) %>% 
  drop_na(odor)
```



# Multinomial Logistic Regression

```{r}
# the odor would be the target variable 

full_model <- multinom(as.factor(odor) ~ .,
                      data = train_rates)

summary(full_model)

info <- broom::tidy(full_model, conf.int = TRUE)
info <- dplyr::filter(info, term != "(Intercept)")
info
```

### Testing Model

```{r}
test_rates <- 
  test_rates %>% 
  mutate(pred_odor = predict(full_model, newdata = test_rates, "class"))

classification_table <- table(test_rates$odor, test_rates$pred_odor)
classification_table

misclassification_err <- mean(as.character(test_rates$pred_odor) != as.character(test_rates$odor))
misclassification_err

```


### PCA (Giles)

```{r}
train_no_zeros <- train_rates %>%
  select(where(~ any(. != 0))) %>% 
  select(-odor)

test_no_zeros <- test_rates[, colnames(train_no_zeros)]

train_pca_w_scale <- prcomp(train_no_zeros, center = TRUE, scale. = TRUE) 

summary(train_pca_w_scale)
# first 15 principal components explain about 60% of the variance

ggbiplot(train_pca_w_scale) +
  ggtitle("PCA of Training Data Set")+
  theme_minimal() +
  theme(legend.position = "bottom")


trg <- predict(train_pca_w_scale, train_no_zeros) 
trg <- data.frame(trg, train_rates$odor) %>% 
  dplyr::rename(odor = train_rates.odor)

tst <- predict(train_pca_w_scale, test_no_zeros) 
tst <- data.frame(tst, test_rates$odor) %>% 
  dplyr::rename(odor = test_rates.odor)

pca_model <- multinom(odor ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 +
                        PC7 + PC8 + PC9 + PC10 + PC11 + PC12 +
                        PC13 + PC14 + PC15 + PC16 + PC17 + PC18 + PC19, 
                      data = trg)
summary(pca_model)

train_pred <- predict(pca_model, trg)
train_tab <- table(train_pred, trg$odor)
train_tab

sum(diag(train_tab))/sum(train_tab)

mean(as.character(train_pred) != as.character(trg$odor))

test_pred <- predict(pca_model, tst)
test_tab <- table(test_pred, tst$odor)
test_tab


sum(diag(test_tab))/sum(test_tab)
mean(as.character(test_pred) != as.character(tst$odor))

```


### Lasso Model Trained On Timeframe 0 to 250 ms

```{r}
#define response variable
y <- train_rates$odor

#define matrix of predictor variables
x <- data.matrix(train_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cv_model <- cv.glmnet(x, y, alpha = 1)

best_lambda <- cv_model$lambda.min
best_lambda

plot(cv_model) 

best_model <- glmnet(x, y, family = "multinomial", alpha = 1, lambda = best_lambda)
coef(best_model)



y_test <- test_rates$odor

#define matrix of predictor variables
x_test <- data.matrix(test_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

```

### Testing Lasso Model Trained On Timeframe 0 to 250 ms

```{r}
cnf <- confusion.glmnet(best_model, x_test, y_test)
cnf

y_hat <- predict(best_model, x_test, s=0.01, type='class')
#y_hat

mean(as.character(y_hat) != as.character(y_test))

n <- sum(cnf) # number of instances
nc <- ncol(cnf) # number of classes
rowsums <- apply(cnf, 1, sum) # number of instances per class
colsums <- apply(cnf, 2, sum) # number of predictions per class
diag <- diag(cnf)  # number of correctly classified instances per class 

precision <- diag / colsums 
recall <- diag / rowsums 
f1 = 2 * precision * recall / (precision + recall) 

max_length <- max(c(length(precision), length(recall), length(f1)))

print(" ************ Confusion Matrix ************")
print(cnf)
print(" ************ Diag ************")
print(diag)
print(" ************ Precision/Recall/F1 ************")
print(data.frame(precision = c(precision, rep(NA, max_length - length(precision))),
           recall = c(recall, rep(NA, max_length - length(recall))),
           f1 = c(f1, rep(NA, max_length - length(f1))))) 

macroPrecision <- mean(precision, na.rm = TRUE)
macroRecall <- mean(recall, na.rm = TRUE)
macroF1 <- mean(f1, na.rm = TRUE)

print(" ************ Macro Precision/Recall/F1 ************")
print(data.frame(macroPrecision, macroRecall, macroF1)) 
```

# Training Data Using 250 to 500 ms Window

### Lasso Model Trained On Timeframe 250 to 500 ms

```{r}
start_window <- 250
end_window <- 500 
window_size <- end_window - start_window

train <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(start_window:end_window) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial)
  #drop_na(odor)
  
test <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(-(start_window:end_window)) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial) 
  #drop_na(odor)

trial_times <- em_trials_odors %>% 
  group_by(trial) %>% 
  dplyr::summarise(trial_time_ms = n()) %>% 
  pull()

test_trial_times <- trial_times - window_size
train_trial_times <- trial_times - test_trial_times

test_rates <- test
train_rates <- train

train_odors <- train %>% 
  select(odor)
test_odors <- test %>% 
  select(odor)

test_rates <- test_rates %>% 
  select(-odor) 
train_rates <- train_rates %>% 
  select(-odor) 

test_rates <- test_rates / trial_times
train_rates <- train_rates / trial_times
  
train_rates <- cbind(train_rates, train_odors) %>% 
  drop_na(odor)
test_rates <- cbind(test_rates, test_odors) %>% 
  drop_na(odor)


#define response variable
y <- train_rates$odor

#define matrix of predictor variables
x <- data.matrix(train_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cv_model <- cv.glmnet(x, y, alpha = 1)

best_lambda <- cv_model$lambda.min
best_lambda

plot(cv_model) 

best_model <- glmnet(x, y, family = "multinomial", alpha = 1, lambda = best_lambda)
coef(best_model)



y_test <- test_rates$odor

#define matrix of predictor variables
x_test <- data.matrix(test_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cnf <- confusion.glmnet(best_model, x_test, y_test)
cnf

y_hat <- predict(best_model, x_test, s=0.01, type='class')
#y_hat

mean(as.character(y_hat) != as.character(y_test))

n <- sum(cnf) # number of instances
nc <- ncol(cnf) # number of classes
rowsums <- apply(cnf, 1, sum) # number of instances per class
colsums <- apply(cnf, 2, sum) # number of predictions per class
diag <- diag(cnf)  # number of correctly classified instances per class 

precision <- diag / colsums 
recall <- diag / rowsums 
f1 = 2 * precision * recall / (precision + recall) 

max_length <- max(c(length(precision), length(recall), length(f1)))

print(" ************ Confusion Matrix ************")
print(cnf)
print(" ************ Diag ************")
print(diag)
print(" ************ Precision/Recall/F1 ************")
print(data.frame(precision = c(precision, rep(NA, max_length - length(precision))),
           recall = c(recall, rep(NA, max_length - length(recall))),
           f1 = c(f1, rep(NA, max_length - length(f1))))) 

macroPrecision <- mean(precision, na.rm = TRUE)
macroRecall <- mean(recall, na.rm = TRUE)
macroF1 <- mean(f1, na.rm = TRUE)

print(" ************ Macro Precision/Recall/F1 ************")
print(data.frame(macroPrecision, macroRecall, macroF1)) 

```

# Training Data Using 500 to 750 ms Window

### Lasso Model Trained On Timeframe 500 to 750 ms

```{r}
start_window <- 500
end_window <- 750 
window_size <- end_window - start_window

train <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(start_window:end_window) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial)
  #drop_na(odor)
  
test <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(-(start_window:end_window)) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial) 
  #drop_na(odor)

trial_times <- em_trials_odors %>% 
  group_by(trial) %>% 
  dplyr::summarise(trial_time_ms = n()) %>% 
  pull()

test_trial_times <- trial_times - window_size
train_trial_times <- trial_times - test_trial_times

test_rates <- test
train_rates <- train

train_odors <- train %>% 
  select(odor)
test_odors <- test %>% 
  select(odor)

test_rates <- test_rates %>% 
  select(-odor) 
train_rates <- train_rates %>% 
  select(-odor) 

test_rates <- test_rates / trial_times
train_rates <- train_rates / trial_times
  
train_rates <- cbind(train_rates, train_odors) %>% 
  drop_na(odor)
test_rates <- cbind(test_rates, test_odors) %>% 
  drop_na(odor)


#define response variable
y <- train_rates$odor

#define matrix of predictor variables
x <- data.matrix(train_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cv_model <- cv.glmnet(x, y, alpha = 1)

best_lambda <- cv_model$lambda.min
best_lambda

plot(cv_model) 

best_model <- glmnet(x, y, family = "multinomial", alpha = 1, lambda = best_lambda)
coef(best_model)



y_test <- test_rates$odor

#define matrix of predictor variables
x_test <- data.matrix(test_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cnf <- confusion.glmnet(best_model, x_test, y_test)
cnf

y_hat <- predict(best_model, x_test, s=0.01, type='class')
#y_hat

mean(as.character(y_hat) != as.character(y_test))

n <- sum(cnf) # number of instances
nc <- ncol(cnf) # number of classes
rowsums <- apply(cnf, 1, sum) # number of instances per class
colsums <- apply(cnf, 2, sum) # number of predictions per class
diag <- diag(cnf)  # number of correctly classified instances per class 

precision <- diag / colsums 
recall <- diag / rowsums 
f1 = 2 * precision * recall / (precision + recall) 

max_length <- max(c(length(precision), length(recall), length(f1)))

print(" ************ Confusion Matrix ************")
print(cnf)
print(" ************ Diag ************")
print(diag)
print(" ************ Precision/Recall/F1 ************")
print(data.frame(precision = c(precision, rep(NA, max_length - length(precision))),
           recall = c(recall, rep(NA, max_length - length(recall))),
           f1 = c(f1, rep(NA, max_length - length(f1))))) 

macroPrecision <- mean(precision, na.rm = TRUE)
macroRecall <- mean(recall, na.rm = TRUE)
macroF1 <- mean(f1, na.rm = TRUE)

print(" ************ Macro Precision/Recall/F1 ************")
print(data.frame(macroPrecision, macroRecall, macroF1)) 

```

# Training Data Using 750 to 1000 ms Window

### Lasso Model Trained On Timeframe 500 to 750 ms

```{r}
start_window <- 750
end_window <- 1000 
window_size <- end_window - start_window

train <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(start_window:end_window) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial)
  #drop_na(odor)
  
test <- em_trials_odors %>% 
  group_by(trial) %>% 
  slice(-(start_window:end_window)) %>% 
  dplyr::summarise(across(neuron_1:neuron_46, sum)) %>% 
  mutate(odor = case_when(
    trial %in% odor_1_trials ~ 1,
    trial %in% odor_2_trials ~ 2,
    trial %in% odor_3_trials ~ 3,
    trial %in% odor_4_trials ~ 4,
    trial %in% odor_5_trials ~ 5
  )) %>%
  select(-trial) 
  #drop_na(odor)

trial_times <- em_trials_odors %>% 
  group_by(trial) %>% 
  dplyr::summarise(trial_time_ms = n()) %>% 
  pull()

test_trial_times <- trial_times - window_size
train_trial_times <- trial_times - test_trial_times

test_rates <- test
train_rates <- train

train_odors <- train %>% 
  select(odor)
test_odors <- test %>% 
  select(odor)

test_rates <- test_rates %>% 
  select(-odor) 
train_rates <- train_rates %>% 
  select(-odor) 

test_rates <- test_rates / trial_times
train_rates <- train_rates / trial_times
  
train_rates <- cbind(train_rates, train_odors) %>% 
  drop_na(odor)
test_rates <- cbind(test_rates, test_odors) %>% 
  drop_na(odor)


#define response variable
y <- train_rates$odor

#define matrix of predictor variables
x <- data.matrix(train_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cv_model <- cv.glmnet(x, y, alpha = 1)

best_lambda <- cv_model$lambda.min
best_lambda

plot(cv_model) 

best_model <- glmnet(x, y, family = "multinomial", alpha = 1, lambda = best_lambda)
coef(best_model)



y_test <- test_rates$odor

#define matrix of predictor variables
x_test <- data.matrix(test_rates[, c('neuron_1', 'neuron_2', 'neuron_3', 'neuron_4', 'neuron_5', 'neuron_6',
                           'neuron_7', 'neuron_8', 'neuron_9', 'neuron_10', 'neuron_11', 'neuron_12',
                           'neuron_13', 'neuron_13', 'neuron_14', 'neuron_15', 'neuron_16', 'neuron_17',
                           'neuron_18', 'neuron_19', 'neuron_20', 'neuron_21', 'neuron_22', 'neuron_23',
                           'neuron_24', 'neuron_25', 'neuron_26', 'neuron_27', 'neuron_28', 'neuron_29',
                           'neuron_30', 'neuron_31', 'neuron_32', 'neuron_33', 'neuron_34', 'neuron_35',
                           'neuron_36', 'neuron_37', 'neuron_38', 'neuron_39', 'neuron_40', 'neuron_41',
                           'neuron_42', 'neuron_43', 'neuron_44', 'neuron_45', 'neuron_46')])

cnf <- confusion.glmnet(best_model, x_test, y_test)
cnf

y_hat <- predict(best_model, x_test, s=0.01, type='class')
#y_hat

mean(as.character(y_hat) != as.character(y_test))

n <- sum(cnf) # number of instances
nc <- ncol(cnf) # number of classes
rowsums <- apply(cnf, 1, sum) # number of instances per class
colsums <- apply(cnf, 2, sum) # number of predictions per class
diag <- diag(cnf)  # number of correctly classified instances per class 

precision <- diag / colsums 
recall <- diag / rowsums 
f1 = 2 * precision * recall / (precision + recall) 

max_length <- max(c(length(precision), length(recall), length(f1)))

print(" ************ Confusion Matrix ************")
print(cnf)
print(" ************ Diag ************")
print(diag)
print(" ************ Precision/Recall/F1 ************")
print(data.frame(precision = c(precision, rep(NA, max_length - length(precision))),
           recall = c(recall, rep(NA, max_length - length(recall))),
           f1 = c(f1, rep(NA, max_length - length(f1))))) 

macroPrecision <- mean(precision, na.rm = TRUE)
macroRecall <- mean(recall, na.rm = TRUE)
macroF1 <- mean(f1, na.rm = TRUE)

print(" ************ Macro Precision/Recall/F1 ************")
print(data.frame(macroPrecision, macroRecall, macroF1)) 
```
